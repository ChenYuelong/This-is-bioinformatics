{"compress":true,"commitItems":[["19c372fb-39b9-4de7-bfbe-6c0ab57dd87d",1519955845366,"---\nstyle: plain\n---\n\nSystematic bias of correlation coefficient may explain negative accuracy of genomic prediction\n=====\n\n[[toc]]\n\n\n\n## 摘要\n\n基因组预测的准确性一般是基于交叉验证及pearson相关系数来计算。但是有很多`negative accuracies`（不是特别好翻译，后文都用`NA`来代表）出现在研究文章中。`NA`描述的就是当表型和基因型是随机打乱的时候，计算出来的pearson相关系数说描述的准确性，这个值应该是在0左右。文中描述了两种用来计算`NA`的方法（Hold accuracy和Instant accuracy）。利用真实及模拟数据测试，确定两种方法在不同的条件下确实会有偏。最终还提出了一种对于Instant accuracy方法的一种改进。\n\n>Accuracy of genomic prediction is commonly calculated as the Pearson correlation coefficient between the predicted and observed phenotypes in the inference population by using cross-validation analysis. More frequently than expected, significant negative accuracies of genomic prediction have been reported in genomic selection studies. These negative values are surprising, given that the minimum value for prediction accuracy should hover around zero when randomly permuted data sets are analyzed.We reviewed the two common approaches for calculating the Pearson correlation and hypothesized that these negative accuracy values reflect potential bias owing to artifacts caused by the mathematical formulas used to calculate prediction accuracy. The first approach, Instant accuracy, calculates correlations for each fold and reports prediction accuracy as themean of correlations across fold. The other approach, Hold accuracy, predicts all phenotypes in all fold and calculates correlation between the observed and predicted phenotypes at the end of the cross validation process. Using simulated and real data,we demonstrated that our hypothesis is true. Both approaches are biased downward under certain conditions. The biases become larger when more fold are employed and when the expected accuracy is low. The bias of Instant accuracy can be corrected using a modified formula.\n\n## 主要方法描述\n\n### 交叉验证（cross-validation）\n\n将样本分成两个不同的部分，一部分用来做training，一部分用来做test。因为样本本身是有正确标签的，用来做test的样本的预测标签和真实标签之前的差异或者一致性可以用来评估模型的好坏，在模型建立及验证中经常使用。\n\n而将这种分成两个部分的实验重复N次，就是N倍交叉验证。常用的有2 fold-cross-validation、5 fold-cross-validation、10 fold-cross-validation。\n\n以2倍交叉验证为例，例如有样本集合[A1，A2，A3，A4，A5，A6]，6个样本的样本集合。需要将这个样本集合随机分为2部分（set1=[A1,A3,A6],set2=[A2,A4,A5]），先用set1做训练（或者模型构建），在通过模型预测set2，并**计算set2中结果一致性**；再用set2做训练，再通过模型预测set1，并**计算set1中结果一致性**。最终结果来描述模型的好坏。\n\n### Instant accuracy\n\n对于交叉验证，之后结果的评估，一种是分别评估一致性（如上所述），再将一致性取平均。\n\n### Hold accuracy\n\n另一种则是，将所有的预测结果放到一起，再计算一致性。\n\n图示：\n![cross-validation]($res/cross-validation.png)\n\n## 结果\n\n### 数据描述\n\n- 真实数据：4个真实的样本集，包含SNP集合及最终的表型标记\n- 随机数据：利用真实的数据，随机打乱表型标记\n- 模拟数据：缺省\n\n### Artifactual negative correlation between means of references and inferences\n\n文中一般研究均使用的是5倍交叉验证。所以研究者将其中一套真实数据随机分成5个size相同的集合时，分别统计了这5个集合的表型值（吐丝时间：连续值），结果如下图所示：\n\n![figure1]($res/figure1.png)\n>Negative correlation between means of references and inferences in cross-validation. The phenotype evaluated was flowering time, measured as DTS, from 260 maize inbred lines. The flowering-time phenotypes were randomly clustered into five evenly-sized groups, indicated by different signs (A). The phenotypic distribution for each group is illustrated in (B). The group numbers in (B) match the group numbers in (C). The signs in (C) match the group signs in (A). The means of inferences are indicated by open signs (C). The means of the other four groups as references are indicated by the filled signs for each inference group. The means of inference and reference are 100% negatively correlated (D).\n\n这个描述其实我觉得多余，因为是同一个数据集，当把大的数作为set1的时候，那么set2里的数自然更小。所以他们就是会呈现出一种负相关。\n\n### Negative bias of hold accuracies\n\n遗传性评估：_就是将training set训练出来的模型，直接作用training set，然后看结果一致性_\n\n\n\n如前一小节所说，如果training set中的表型均值越大，那么test set中的表型均值则越小。又因为training set中的表型均值更大一些，所以所训练出来的模型就更倾向于预测test set更大的值。有这些关系可以推断出，如果直接使用`Hold accuracies`进行评估，本身就会有一些负相关偏好在其中。其结果如下图所示：\n\n![figure2]($res/figure2.png)\n\n>ABC图表示的训练出的模型对training set作用所获得的结果。DEF则是对test set作用所获得结果。\n\n能从F图中看出，利用`Hold accuracy`的确会有一个偏好。\n\n### More fold leads to more bias using hold accuracy\n\n\n利用交叉验证，使用的倍数越多（More fold），则偏好越大，如下图所示：\n\n![figure3]($res/figure3.png)\n\n\n\n### Differences in prediction accuracy between Hold and Instant approaches\n\n>We extended our examination to scenarios with expected prediction accuracies above zero by using phenotypes simulated from real maize genotypes.\n\n这一部分我的理解是：对于一个数据集，本身是有真实表型的（假设SNP及表型集是100%相关的），然后将本身的真实表型部分打乱，最终达到一个相关度0.125~0.75。然后在按照之前的方法进行分析，同样还会逐步改变样本数目。结果如下图所\n示：\n\n![figure4]($res/figure4.png)\n\n可以发现，这些条件的变化，Instant accuracy都要比Hold accuracy要高。而且在同样的继承性的条件下，样本数目越多，准确度越高。\n\n\n\n### Problems unique to Instant accuracy\n\n前几小节的结论都是Instant accuracy的结果要比Hold accuracy好。但也不是代表Instant accuracy没有问题。由于它是分每一次做一个相关性，然后计算相关性的均值。由于本身pearson相关系数的特性，就是对于小样本量，相关系数会有偏（Fisher大\n神说的），所以当样本量很少的情况下，Instant accuracy结果就会出现问题。如下图所示：\n\n![figure5]($res/figure5.png)\n\n从上图中，可以发现，随着fold数目的增加，test set中的样本越来越少（fold数越多，相当于将样本集平均分成了多少份）准确性会下降。而且这种下降不是由于模型出问题（因为training set的样本数大，所以模型应该是更好的），而只能是算法出现了问题。\n\n\n\n### Correcting Instant accuracy toward unbiased estimation\n\n文中使用了一个矫正方法（并非作者发明，而是之前其他人发表，但是并没有用到这项评估中，所以作者提议以后加入这项矫正），结果就要好的多，但是因为是计算pearson相关系数，所以还是有一定的数目限制，至少test set中要包含5个样本以上。结果如上图中的黑线。\n\n矫正公式如下：\n\n$$\n\\widehat{p}=r[1+\\frac{(1-r^2)}{2(n-4)}]\n$$\n其中n为样本数，r为pearson相关系数\n\n## 讨论\n\n### Biased Hold accuracy under the null hypothesis\n\n前人研究中只是展示了偏好，但是并没有分析出原因。\n\n\n## Take Home Message\n\n1. 因为几乎没有做过此类研究，所以算第一次看到用相关系数来评判模型好坏的文章，之后如果用于机器学习，regression可以尝试用这种方法来评估性能。\n2. 有些差异就是机器学习的regression都是利用差值来进行寻找最小误差，从而获得最优模型。最终评估结果也是利用差异大小来评估，使用差值就不存在Instant accuracy和Hold accuracy了。\n\n\n$$\n\\frac{\\frac{(x_1-\\hat{x})^2+(x_2-\\hat{x})^2}{2}+\\frac{(x_3-\\hat{x})^2+(x_4-\\hat{x})^2}{2}}{2}=\\frac{(x_1-\\hat{x})^2+(x_2-\\hat{x})^2+(x_3-\\hat{x})^2+(x_4-\\hat{x})^2}{4}\n$$\n上述是一样的。所以利用差值是不存在这种情况。以后如果做类似的工作，可以试试使用pearson相关系数来进行结果评估。\n\n\n",[[1519955837988,["yuelong.chen@EIBJDE0195",[[1,2368,"\n"],[-1,2388,"$r"],[1,2390,"imag"],[1,2414,"\n"]],[2368,2414],[2418,2418]]],[1519955845176,["yuelong.chen@EIBJDE0195",[[-1,2369,"![cross-validation](images/cross-validation.png)"]],[2369,2417],[2369,2369]]],[1519955850400,["yuelong.chen@EIBJDE0195",[[1,2370,"![cross-validation](images/cross-validation.png)\n\n"]],[2369,2369],[2419,2419]]],[1519955872247,["yuelong.chen@EIBJDE0195",[[-1,2682,"$r"],[1,2684,"imag"]],[2682,2686],[2688,2688]]],[1519955876131,["yuelong.chen@EIBJDE0195",[[-1,3758,"$r"],[1,3760,"imag"]],[3758,3762],[3764,3764]]],[1519955879048,["yuelong.chen@EIBJDE0195",[[-1,3981,"$r"],[1,3983,"imag"]],[3981,3985],[3987,3987]]],[1519955882912,["yuelong.chen@EIBJDE0195",[[-1,4359,"$r"],[1,4361,"imag"]],[4359,4363],[4365,4365]]],[1519955885272,["yuelong.chen@EIBJDE0195",[[-1,4704,"$r"],[1,4706,"imag"]],[4704,4708],[4710,4710]]]]],["5dba1492-0724-40b5-9ae9-9734defccf64",1519956652173,"---\nstyle: plain\n---\n\nSystematic bias of correlation coefficient may explain negative accuracy of genomic prediction\n=====\n\n[[toc]]\n\n\n\n## 摘要\n\n基因组预测的准确性一般是基于交叉验证及pearson相关系数来计算。但是有很多`negative accuracies`（不是特别好翻译，后文都用`NA`来代表）出现在研究文章中。`NA`描述的就是当表型和基因型是随机打乱的时候，计算出来的pearson相关系数说描述的准确性，这个值应该是在0左右。文中描述了两种用来计算`NA`的方法（Hold accuracy和Instant accuracy）。利用真实及模拟数据测试，确定两种方法在不同的条件下确实会有偏。最终还提出了一种对于Instant accuracy方法的一种改进。\n\n>Accuracy of genomic prediction is commonly calculated as the Pearson correlation coefficient between the predicted and observed phenotypes in the inference population by using cross-validation analysis. More frequently than expected, significant negative accuracies of genomic prediction have been reported in genomic selection studies. These negative values are surprising, given that the minimum value for prediction accuracy should hover around zero when randomly permuted data sets are analyzed.We reviewed the two common approaches for calculating the Pearson correlation and hypothesized that these negative accuracy values reflect potential bias owing to artifacts caused by the mathematical formulas used to calculate prediction accuracy. The first approach, Instant accuracy, calculates correlations for each fold and reports prediction accuracy as themean of correlations across fold. The other approach, Hold accuracy, predicts all phenotypes in all fold and calculates correlation between the observed and predicted phenotypes at the end of the cross validation process. Using simulated and real data,we demonstrated that our hypothesis is true. Both approaches are biased downward under certain conditions. The biases become larger when more fold are employed and when the expected accuracy is low. The bias of Instant accuracy can be corrected using a modified formula.\n\n## 主要方法描述\n\n### 交叉验证（cross-validation）\n\n将样本分成两个不同的部分，一部分用来做training，一部分用来做test。因为样本本身是有正确标签的，用来做test的样本的预测标签和真实标签之前的差异或者一致性可以用来评估模型的好坏，在模型建立及验证中经常使用。\n\n而将这种分成两个部分的实验重复N次，就是N倍交叉验证。常用的有2 fold-cross-validation、5 fold-cross-validation、10 fold-cross-validation。\n\n以2倍交叉验证为例，例如有样本集合[A1，A2，A3，A4，A5，A6]，6个样本的样本集合。需要将这个样本集合随机分为2部分（set1=[A1,A3,A6],set2=[A2,A4,A5]），先用set1做训练（或者模型构建），在通过模型预测set2，并**计算set2中结果一致性**；再用set2做训练，再通过模型预测set1，并**计算set1中结果一致性**。最终结果来描述模型的好坏。\n\n### Instant accuracy\n\n对于交叉验证，之后结果的评估，一种是分别评估一致性（如上所述），再将一致性取平均。\n\n### Hold accuracy\n\n另一种则是，将所有的预测结果放到一起，再计算一致性。\n\n图示：\n\n\n![cross-validation](images/cross-validation.png)\n\n\n\n## 结果\n\n### 数据描述\n\n- 真实数据：4个真实的样本集，包含SNP集合及最终的表型标记\n- 随机数据：利用真实的数据，随机打乱表型标记\n- 模拟数据：缺省\n\n### Artifactual negative correlation between means of references and inferences\n\n文中一般研究均使用的是5倍交叉验证。所以研究者将其中一套真实数据随机分成5个size相同的集合时，分别统计了这5个集合的表型值（吐丝时间：连续值），结果如下图所示：\n\n![figure1](images/figure1.png)\n>Negative correlation between means of references and inferences in cross-validation. The phenotype evaluated was flowering time, measured as DTS, from 260 maize inbred lines. The flowering-time phenotypes were randomly clustered into five evenly-sized groups, indicated by different signs (A). The phenotypic distribution for each group is illustrated in (B). The group numbers in (B) match the group numbers in (C). The signs in (C) match the group signs in (A). The means of inferences are indicated by open signs (C). The means of the other four groups as references are indicated by the filled signs for each inference group. The means of inference and reference are 100% negatively correlated (D).\n\n这个描述其实我觉得多余，因为是同一个数据集，当把大的数作为set1的时候，那么set2里的数自然更小。所以他们就是会呈现出一种负相关。\n\n### Negative bias of hold accuracies\n\n遗传性评估：_就是将training set训练出来的模型，直接作用training set，然后看结果一致性_\n\n\n\n如前一小节所说，如果training set中的表型均值越大，那么test set中的表型均值则越小。又因为training set中的表型均值更大一些，所以所训练出来的模型就更倾向于预测test set更大的值。有这些关系可以推断出，如果直接使用`Hold accuracies`进行评估，本身就会有一些负相关偏好在其中。其结果如下图所示：\n\n![figure2](images/figure2.png)\n\n>ABC图表示的训练出的模型对training set作用所获得的结果。DEF则是对test set作用所获得结果。\n\n能从F图中看出，利用`Hold accuracy`的确会有一个偏好。\n\n### More fold leads to more bias using hold accuracy\n\n\n利用交叉验证，使用的倍数越多（More fold），则偏好越大，如下图所示：\n\n![figure3](images/figure3.png)\n\n\n\n### Differences in prediction accuracy between Hold and Instant approaches\n\n>We extended our examination to scenarios with expected prediction accuracies above zero by using phenotypes simulated from real maize genotypes.\n\n这一部分我的理解是：对于一个数据集，本身是有真实表型的（假设SNP及表型集是100%相关的），然后将本身的真实表型部分打乱，最终达到一个相关度0.125~0.75。然后在按照之前的方法进行分析，同样还会逐步改变样本数目。结果如下图所\n示：\n\n![figure4](images/figure4.png)\n\n可以发现，这些条件的变化，Instant accuracy都要比Hold accuracy要高。而且在同样的继承性的条件下，样本数目越多，准确度越高。\n\n\n\n### Problems unique to Instant accuracy\n\n前几小节的结论都是Instant accuracy的结果要比Hold accuracy好。但也不是代表Instant accuracy没有问题。由于它是分每一次做一个相关性，然后计算相关性的均值。由于本身pearson相关系数的特性，就是对于小样本量，相关系数会有偏（Fisher大\n神说的），所以当样本量很少的情况下，Instant accuracy结果就会出现问题。如下图所示：\n\n![figure5](images/figure5.png)\n\n从上图中，可以发现，随着fold数目的增加，test set中的样本越来越少（fold数越多，相当于将样本集平均分成了多少份）准确性会下降。而且这种下降不是由于模型出问题（因为training set的样本数大，所以模型应该是更好的），而只能是算法出现了问题。\n\n\n\n### Correcting Instant accuracy toward unbiased estimation\n\n文中使用了一个矫正方法（并非作者发明，而是之前其他人发表，但是并没有用到这项评估中，所以作者提议以后加入这项矫正），结果就要好的多，但是因为是计算pearson相关系数，所以还是有一定的数目限制，至少test set中要包含5个样本以上。结果如上图中的黑线。\n\n矫正公式如下：\n\n$$\n\\widehat{p}=r[1+\\frac{(1-r^2)}{2(n-4)}]\n$$\n其中n为样本数，r为pearson相关系数\n\n## 讨论\n\n### Biased Hold accuracy under the null hypothesis\n\n前人研究中只是展示了偏好，但是并没有分析出原因。\n\n\n## Take Home Message\n\n1. 因为几乎没有做过此类研究，所以算第一次看到用相关系数来评判模型好坏的文章，之后如果用于机器学习，regression可以尝试用这种方法来评估性能。\n2. 有些差异就是机器学习的regression都是利用差值来进行寻找最小误差，从而获得最优模型。最终评估结果也是利用差异大小来评估，使用差值就不存在Instant accuracy和Hold accuracy了。\n\n\n$$\n\\frac{\\frac{(x_1-\\hat{x})^2+(x_2-\\hat{x})^2}{2}+\\frac{(x_3-\\hat{x})^2+(x_4-\\hat{x})^2}{2}}{2}=\\frac{(x_1-\\hat{x})^2+(x_2-\\hat{x})^2+(x_3-\\hat{x})^2+(x_4-\\hat{x})^2}{4}\n$$\n上述是一样的。所以利用差值是不存在这种情况。以后如果做类似的工作，可以试试使用pearson相关系数来进行结果评估。\n\n\n",[[1519956596336,["yuelong.chen@EIBJDE0195",[[-1,124,"[[toc]]"]],[124,131],[124,124]]],[1519956598455,["yuelong.chen@EIBJDE0195",[[-1,127,"\n"]],[124,124],[123,123]]],[1519956600559,["yuelong.chen@EIBJDE0195",[[-1,126,"\n"]],[126,126],[125,125]]],[1519956600774,["yuelong.chen@EIBJDE0195",[[-1,125,"\n"]],[125,125],[124,124]]],[1519956601018,["yuelong.chen@EIBJDE0195",[[-1,124,"\n"]],[124,124],[123,123]]],[1519956620970,["yuelong.chen@EIBJDE0195",[[1,2379,"../"]],[2379,2379],[2382,2382]]],[1519956626095,["yuelong.chen@EIBJDE0195",[[-1,2379,"../"]],[2382,2382],[2379,2379]]]]],["01b581c0-4169-4146-a5ee-01242bc8f85b",1519957080952,"---\nstyle: plain\n---\n\n<<<<<<< HEAD\n<<<<<<< HEAD\nSystematic bias of correlation coefficient may explain negative accuracy of genomic prediction\n=====\n=======\n=======\n>>>>>>> 17ce46d3fc273a45fc5b058eebdb4e81eda9827f\n# Systematic bias of correlation coefficient may explain negative accuracy of genomic prediction\n\n\n>>>>>>> 17ce46d3fc273a45fc5b058eebdb4e81eda9827f\n\n## 摘要\n\n基因组预测的准确性一般是基于交叉验证及pearson相关系数来计算。但是有很多`negative accuracies`（不是特别好翻译，后文都用`NA`来代表）出现在研究文章中。`NA`描述的就是当表型和基因型是随机打乱的时候，计算出来的pearson相关系数说描述的准确性，这个值应该是在0左右。文中描述了两种用来计算`NA`的方法（Hold accuracy和Instant accuracy）。利用真实及模拟数据测试，确定两种方法在不同的条件下确实会有偏。最终还提出了一种对于Instant accuracy方法的一种改进。\n\n> Accuracy of genomic prediction is commonly calculated as the Pearson correlation coefficient between the predicted and observed phenotypes in the inference population by using cross-validation analysis. More frequently than expected, significant negative accuracies of genomic prediction have been reported in genomic selection studies. These negative values are surprising, given that the minimum value for prediction accuracy should hover around zero when randomly permuted data sets are analyzed.We reviewed the two common approaches for calculating the Pearson correlation and hypothesized that these negative accuracy values reflect potential bias owing to artifacts caused by the mathematical formulas used to calculate prediction accuracy. The first approach, Instant accuracy, calculates correlations for each fold and reports prediction accuracy as themean of correlations across fold. The other approach, Hold accuracy, predicts all phenotypes in all fold and calculates correlation between the observed and predicted phenotypes at the end of the cross validation process. Using simulated and real data,we demonstrated that our hypothesis is true. Both approaches are biased downward under certain conditions. The biases become larger when more fold are employed and when the expected accuracy is low. The bias of Instant accuracy can be corrected using a modified formula.\n\n## 主要方法描述\n\n### 交叉验证（cross-validation）\n\n将样本分成两个不同的部分，一部分用来做training，一部分用来做test。因为样本本身是有正确标签的，用来做test的样本的预测标签和真实标签之前的差异或者一致性可以用来评估模型的好坏，在模型建立及验证中经常使用。\n\n而将这种分成两个部分的实验重复N次，就是N倍交叉验证。常用的有2 fold-cross-validation、5 fold-cross-validation、10 fold-cross-validation。\n\n以2倍交叉验证为例，例如有样本集合\\[A1，A2，A3，A4，A5，A6\\]，6个样本的样本集合。需要将这个样本集合随机分为2部分（set1=\\[A1,A3,A6\\],set2=\\[A2,A4,A5\\]），先用set1做训练（或者模型构建），在通过模型预测set2，并**计算set2中结果一致性**；再用set2做训练，再通过模型预测set1，并**计算set1中结果一致性**。最终结果来描述模型的好坏。\n\n### Instant accuracy\n\n对于交叉验证，之后结果的评估，一种是分别评估一致性（如上所述），再将一致性取平均。\n\n### Hold accuracy\n\n另一种则是，将所有的预测结果放到一起，再计算一致性。\n\n图示：\n\n![](/images/cross-validation.png)\n\n## 结果\n\n### 数据描述\n\n* 真实数据：4个真实的样本集，包含SNP集合及最终的表型标记\n* 随机数据：利用真实的数据，随机打乱表型标记\n* 模拟数据：缺省\n\n### Artifactual negative correlation between means of references and inferences\n\n文中一般研究均使用的是5倍交叉验证。所以研究者将其中一套真实数据随机分成5个size相同的集合时，分别统计了这5个集合的表型值（吐丝时间：连续值），结果如下图所示：\n\n![](/images/figure1.png)\n\n> Negative correlation between means of references and inferences in cross-validation. The phenotype evaluated was flowering time, measured as DTS, from 260 maize inbred lines. The flowering-time phenotypes were randomly clustered into five evenly-sized groups, indicated by different signs \\(A\\). The phenotypic distribution for each group is illustrated in \\(B\\). The group numbers in \\(B\\) match the group numbers in \\(C\\). The signs in \\(C\\) match the group signs in \\(A\\). The means of inferences are indicated by open signs \\(C\\). The means of the other four groups as references are indicated by the filled signs for each inference group. The means of inference and reference are 100% negatively correlated \\(D\\).\n\n这个描述其实我觉得多余，因为是同一个数据集，当把大的数作为set1的时候，那么set2里的数自然更小。所以他们就是会呈现出一种负相关。\n\n### Negative bias of hold accuracies\n\n遗传性评估：_就是将training set训练出来的模型，直接作用training set，然后看结果一致性_\n\n如前一小节所说，如果training set中的表型均值越大，那么test set中的表型均值则越小。又因为training set中的表型均值更大一些，所以所训练出来的模型就更倾向于预测test set更大的值。有这些关系可以推断出，如果直接使用`Hold accuracies`进行评估，本身就会有一些负相关偏好在其中。其结果如下图所示：\n\n![](/images/figure2.png)\n\n> ABC图表示的训练出的模型对training set作用所获得的结果。DEF则是对test set作用所获得结果。\n\n能从F图中看出，利用`Hold accuracy`的确会有一个偏好。\n\n### More fold leads to more bias using hold accuracy\n\n利用交叉验证，使用的倍数越多（More fold），则偏好越大，如下图所示：\n\n![](/images/figure3.png)\n\n### Differences in prediction accuracy between Hold and Instant approaches\n\n> We extended our examination to scenarios with expected prediction accuracies above zero by using phenotypes simulated from real maize genotypes.\n\n这一部分我的理解是：对于一个数据集，本身是有真实表型的（假设SNP及表型集是100%相关的），然后将本身的真实表型部分打乱，最终达到一个相关度0.125~0.75。然后在按照之前的方法进行分析，同样还会逐步改变样本数目。结果如下图所  \n示：\n\n![](/images/figure4.png)\n\n可以发现，这些条件的变化，Instant accuracy都要比Hold accuracy要高。而且在同样的继承性的条件下，样本数目越多，准确度越高。\n\n### Problems unique to Instant accuracy\n\n前几小节的结论都是Instant accuracy的结果要比Hold accuracy好。但也不是代表Instant accuracy没有问题。由于它是分每一次做一个相关性，然后计算相关性的均值。由于本身pearson相关系数的特性，就是对于小样本量，相关系数会有偏（Fisher大  \n神说的），所以当样本量很少的情况下，Instant accuracy结果就会出现问题。如下图所示：\n\n![](/images/figure5.png)\n\n从上图中，可以发现，随着fold数目的增加，test set中的样本越来越少（fold数越多，相当于将样本集平均分成了多少份）准确性会下降。而且这种下降不是由于模型出问题（因为training set的样本数大，所以模型应该是更好的），而只能是算法出现了问题。\n\n### Correcting Instant accuracy toward unbiased estimation\n\n文中使用了一个矫正方法（并非作者发明，而是之前其他人发表，但是并没有用到这项评估中，所以作者提议以后加入这项矫正），结果就要好的多，但是因为是计算pearson相关系数，所以还是有一定的数目限制，至少test set中要包含5个样本以上。结果如上图中的黑线。\n\n矫正公式如下：\n\n\n$$\n\\widehat{p}=r[1+\\frac{(1-r^2)}{2(n-4)}]\n$$\n\n\n其中n为样本数，r为pearson相关系数\n\n## 讨论\n\n### Biased Hold accuracy under the null hypothesis\n\n前人研究中只是展示了偏好，但是并没有分析出原因。\n\n## Take Home Message\n\n1. 因为几乎没有做过此类研究，所以算第一次看到用相关系数来评判模型好坏的文章，之后如果用于机器学习，regression可以尝试用这种方法来评估性能。\n2. 有些差异就是机器学习的regression都是利用差值来进行寻找最小误差，从而获得最优模型。最终评估结果也是利用差异大小来评估，使用差值就不存在Instant accuracy和Hold accuracy了。\n\n\n$$\n\\frac{\\frac{(x_1-\\hat{x})^2+(x_2-\\hat{x})^2}{2}+\\frac{(x_3-\\hat{x})^2+(x_4-\\hat{x})^2}{2}}{2}=\\frac{(x_1-\\hat{x})^2+(x_2-\\hat{x})^2+(x_3-\\hat{x})^2+(x_4-\\hat{x})^2}{4}\n$$\n\n\n上述是一样的。所以利用差值是不存在这种情况。以后如果做类似的工作，可以试试使用pearson相关系数来进行结果评估。\n\n",[[1519957064915,["yuelong.chen@EIBJDE0195",[[-1,149,"=======\n=======\n>>>>>>> 17ce46d3fc273a45fc5b058eebdb4e81eda9827f\n# Systematic bias of correlation coefficient may explain negative accuracy of genomic prediction\n\n\n>>>>>>> 17ce46d3fc273a45fc5b058eebdb4e81eda9827f"]],[149,361],[149,149]]],[1519957067960,["yuelong.chen@EIBJDE0195",[[-1,22,"<<<<<<< HEAD\n<<<<<<< HEAD"]],[22,47],[22,22]]],[1519957195239,["yuelong.chen@EIBJDE0195",[[1,5393,"\n"]],[5392,5392],[5393,5393]]],[1519957196753,["yuelong.chen@EIBJDE0195",[[1,5562,"\n"]],[5561,5561],[5562,5562]]],[1519957199791,["yuelong.chen@EIBJDE0195",[[-1,5393,"\n"]],[5394,5394],[5393,5393]]],[1519957200867,["yuelong.chen@EIBJDE0195",[[-1,5392,"\n"]],[5393,5393],[5392,5392]]],[1519957201950,["yuelong.chen@EIBJDE0195",[[-1,5391,"$"]],[5392,5392],[5391,5391]]],[1519957203734,["yuelong.chen@EIBJDE0195",[[-1,5559,"\n"]],[5560,5560],[5559,5559]]],[1519957204543,["yuelong.chen@EIBJDE0195",[[-1,5558,"\n"]],[5559,5559],[5558,5558]]],[1519957206252,["yuelong.chen@EIBJDE0195",[[-1,5559,"$"]],[5558,5558],[5558,5558]]],[1519957210591,["yuelong.chen@EIBJDE0195",[[-1,5067,"\n"]],[5068,5068],[5067,5067]]],[1519957211896,["yuelong.chen@EIBJDE0195",[[-1,5068,"$"]],[5067,5067],[5067,5067]]],[1519957213120,["yuelong.chen@EIBJDE0195",[[-1,5027,"\n"]],[5028,5028],[5027,5027]]],[1519957213686,["yuelong.chen@EIBJDE0195",[[-1,5026,"$"]],[5027,5027],[5026,5026]]]]],["8a34aa6a-ca94-4156-8fc1-be51e36086f7",1519959190818,"---\nstyle: plain\n---\n\n# Systematic bias of correlation coefficient may explain negative accuracy of genomic prediction\n\n## 摘要\n\n基因组预测的准确性一般是基于交叉验证及pearson相关系数来计算。但是有很多`negative accuracies`（不是特别好翻译，后文都用`NA`来代表）出现在研究文章中。`NA`描述的就是当表型和基因型是随机打乱的时候，计算出来的pearson相关系数说描述的准确性，这个值应该是在0左右。文中描述了两种用来计算`NA`的方法（Hold accuracy和Instant accuracy）。利用真实及模拟数据测试，确定两种方法在不同的条件下确实会有偏。最终还提出了一种对于Instant accuracy方法的一种改进。\n\n> Accuracy of genomic prediction is commonly calculated as the Pearson correlation coefficient between the predicted and observed phenotypes in the inference population by using cross-validation analysis. More frequently than expected, significant negative accuracies of genomic prediction have been reported in genomic selection studies. These negative values are surprising, given that the minimum value for prediction accuracy should hover around zero when randomly permuted data sets are analyzed.We reviewed the two common approaches for calculating the Pearson correlation and hypothesized that these negative accuracy values reflect potential bias owing to artifacts caused by the mathematical formulas used to calculate prediction accuracy. The first approach, Instant accuracy, calculates correlations for each fold and reports prediction accuracy as themean of correlations across fold. The other approach, Hold accuracy, predicts all phenotypes in all fold and calculates correlation between the observed and predicted phenotypes at the end of the cross validation process. Using simulated and real data,we demonstrated that our hypothesis is true. Both approaches are biased downward under certain conditions. The biases become larger when more fold are employed and when the expected accuracy is low. The bias of Instant accuracy can be corrected using a modified formula.\n\n## 主要方法描述\n\n### 交叉验证（cross-validation）\n\n将样本分成两个不同的部分，一部分用来做training，一部分用来做test。因为样本本身是有正确标签的，用来做test的样本的预测标签和真实标签之前的差异或者一致性可以用来评估模型的好坏，在模型建立及验证中经常使用。\n\n而将这种分成两个部分的实验重复N次，就是N倍交叉验证。常用的有2 fold-cross-validation、5 fold-cross-validation、10 fold-cross-validation。\n\n以2倍交叉验证为例，例如有样本集合\\[A1，A2，A3，A4，A5，A6\\]，6个样本的样本集合。需要将这个样本集合随机分为2部分（set1=\\[A1,A3,A6\\],set2=\\[A2,A4,A5\\]），先用set1做训练（或者模型构建），在通过模型预测set2，并**计算set2中结果一致性**；再用set2做训练，再通过模型预测set1，并**计算set1中结果一致性**。最终结果来描述模型的好坏。\n\n### Instant accuracy\n\n对于交叉验证，之后结果的评估，一种是分别评估一致性（如上所述），再将一致性取平均。\n\n### Hold accuracy\n\n另一种则是，将所有的预测结果放到一起，再计算一致性。\n\n图示：\n\n![](/images/cross-validation.png)\n\n## 结果\n\n### 数据描述\n\n* 真实数据：4个真实的样本集，包含SNP集合及最终的表型标记\n* 随机数据：利用真实的数据，随机打乱表型标记\n* 模拟数据：缺省\n\n### Artifactual negative correlation between means of references and inferences\n\n文中一般研究均使用的是5倍交叉验证。所以研究者将其中一套真实数据随机分成5个size相同的集合时，分别统计了这5个集合的表型值（吐丝时间：连续值），结果如下图所示：\n\n![](/images/figure1.png)\n\n> Negative correlation between means of references and inferences in cross-validation. The phenotype evaluated was flowering time, measured as DTS, from 260 maize inbred lines. The flowering-time phenotypes were randomly clustered into five evenly-sized groups, indicated by different signs \\(A\\). The phenotypic distribution for each group is illustrated in \\(B\\). The group numbers in \\(B\\) match the group numbers in \\(C\\). The signs in \\(C\\) match the group signs in \\(A\\). The means of inferences are indicated by open signs \\(C\\). The means of the other four groups as references are indicated by the filled signs for each inference group. The means of inference and reference are 100% negatively correlated \\(D\\).\n\n这个描述其实我觉得多余，因为是同一个数据集，当把大的数作为set1的时候，那么set2里的数自然更小。所以他们就是会呈现出一种负相关。\n\n### Negative bias of hold accuracies\n\n遗传性评估：_就是将training set训练出来的模型，直接作用training set，然后看结果一致性_\n\n如前一小节所说，如果training set中的表型均值越大，那么test set中的表型均值则越小。又因为training set中的表型均值更大一些，所以所训练出来的模型就更倾向于预测test set更大的值。有这些关系可以推断出，如果直接使用`Hold accuracies`进行评估，本身就会有一些负相关偏好在其中。其结果如下图所示：\n\n![](/images/figure2.png)\n\n> ABC图表示的训练出的模型对training set作用所获得的结果。DEF则是对test set作用所获得结果。\n\n能从F图中看出，利用`Hold accuracy`的确会有一个偏好。\n\n### More fold leads to more bias using hold accuracy\n\n利用交叉验证，使用的倍数越多（More fold），则偏好越大，如下图所示：\n\n![](/images/figure3.png)\n\n### Differences in prediction accuracy between Hold and Instant approaches\n\n> We extended our examination to scenarios with expected prediction accuracies above zero by using phenotypes simulated from real maize genotypes.\n\n这一部分我的理解是：对于一个数据集，本身是有真实表型的（假设SNP及表型集是100%相关的），然后将本身的真实表型部分打乱，最终达到一个相关度0.125~0.75。然后在按照之前的方法进行分析，同样还会逐步改变样本数目。结果如下图所  \n示：\n\n![](/images/figure4.png)\n\n可以发现，这些条件的变化，Instant accuracy都要比Hold accuracy要高。而且在同样的继承性的条件下，样本数目越多，准确度越高。\n\n### Problems unique to Instant accuracy\n\n前几小节的结论都是Instant accuracy的结果要比Hold accuracy好。但也不是代表Instant accuracy没有问题。由于它是分每一次做一个相关性，然后计算相关性的均值。由于本身pearson相关系数的特性，就是对于小样本量，相关系数会有偏（Fisher大  \n神说的），所以当样本量很少的情况下，Instant accuracy结果就会出现问题。如下图所示：\n\n![](/images/figure5.png)\n\n从上图中，可以发现，随着fold数目的增加，test set中的样本越来越少（fold数越多，相当于将样本集平均分成了多少份）准确性会下降。而且这种下降不是由于模型出问题（因为training set的样本数大，所以模型应该是更好的），而只能是算法出现了问题。\n\n### Correcting Instant accuracy toward unbiased estimation\n\n文中使用了一个矫正方法（并非作者发明，而是之前其他人发表，但是并没有用到这项评估中，所以作者提议以后加入这项矫正），结果就要好的多，但是因为是计算pearson相关系数，所以还是有一定的数目限制，至少test set中要包含5个样本以上。结果如上图中的黑线。\n\n矫正公式如下：\n\n$$\n\n\\widehat{p}=r\\[1+\\frac{\\(1-r^2\\)}{2\\(n-4\\)}\\]\n\n$$\n\n其中n为样本数，r为pearson相关系数\n\n## 讨论\n\n### Biased Hold accuracy under the null hypothesis\n\n前人研究中只是展示了偏好，但是并没有分析出原因。\n\n## Take Home Message\n\n1. 因为几乎没有做过此类研究，所以算第一次看到用相关系数来评判模型好坏的文章，之后如果用于机器学习，regression可以尝试用这种方法来评估性能。\n2. 有些差异就是机器学习的regression都是利用差值来进行寻找最小误差，从而获得最优模型。最终评估结果也是利用差异大小来评估，使用差值就不存在Instant accuracy和Hold accuracy了。\n\n$$\n\n\\frac{\\frac{\\(x\\_1-\\hat{x}\\)^2+\\(x\\_2-\\hat{x}\\)^2}{2}+\\frac{\\(x\\_3-\\hat{x}\\)^2+\\(x\\_4-\\hat{x}\\)^2}{2}}{2}=\\frac{\\(x\\_1-\\hat{x}\\)^2+\\(x\\_2-\\hat{x}\\)^2+\\(x\\_3-\\hat{x}\\)^2+\\(x\\_4-\\hat{x}\\)^2}{4}\n\n$$\n\n上述是一样的。所以利用差值是不存在这种情况。以后如果做类似的工作，可以试试使用pearson相关系数来进行结果评估。\n\n",[[1519959143801,["yuelong.chen@EIBJDE0195",[[-1,5035,"\\"]],[5035,5035],[5035,5035]]],[1519959146112,["yuelong.chen@EIBJDE0195",[[-1,5044,"\\"]],[5044,5044],[5044,5044]]],[1519959147288,["yuelong.chen@EIBJDE0195",[[-1,5050,"\\"]],[5050,5050],[5050,5050]]],[1519959148423,["yuelong.chen@EIBJDE0195",[[-1,5054,"\\"]],[5054,5054],[5054,5054]]],[1519959150440,["yuelong.chen@EIBJDE0195",[[-1,5058,"\\"]],[5058,5058],[5058,5058]]],[1519959151599,["yuelong.chen@EIBJDE0195",[[-1,5060,"\\"]],[5060,5060],[5060,5060]]],[1519959154600,["yuelong.chen@EIBJDE0195",[[-1,5399,"\\"]],[5399,5399],[5399,5399]]],[1519959155662,["yuelong.chen@EIBJDE0195",[[-1,5401,"\\"]],[5401,5401],[5401,5401]]],[1519959157256,["yuelong.chen@EIBJDE0195",[[-1,5411,"\\"]],[5411,5411],[5411,5411]]],[1519959158791,["yuelong.chen@EIBJDE0195",[[-1,5415,"\\"]],[5415,5415],[5415,5415]]],[1519959159816,["yuelong.chen@EIBJDE0195",[[-1,5417,"\\"]],[5417,5417],[5417,5417]]],[1519959162174,["yuelong.chen@EIBJDE0195",[[-1,5427,"\\"]],[5427,5427],[5427,5427]]],[1519959164247,["yuelong.chen@EIBJDE0195",[[-1,5441,"\\"]],[5441,5441],[5441,5441]]],[1519959164999,["yuelong.chen@EIBJDE0195",[[-1,5443,"\\"]],[5443,5443],[5443,5443]]],[1519959167983,["yuelong.chen@EIBJDE0195",[[-1,5453,"\\"]],[5453,5453],[5453,5453]]],[1519959169430,["yuelong.chen@EIBJDE0195",[[-1,5457,"\\"]],[5457,5457],[5457,5457]]],[1519959170468,["yuelong.chen@EIBJDE0195",[[-1,5459,"\\"]],[5459,5459],[5459,5459]]],[1519959174305,["yuelong.chen@EIBJDE0195",[[-1,5488,"\\"]],[5488,5488],[5488,5488]]],[1519959175788,["yuelong.chen@EIBJDE0195",[[-1,5490,"\\"]],[5490,5490],[5490,5490]]],[1519959178433,["yuelong.chen@EIBJDE0195",[[-1,5505,"\\"]],[5505,5505],[5505,5505]]],[1519959179340,["yuelong.chen@EIBJDE0195",[[-1,5507,"\\"]],[5507,5507],[5507,5507]]],[1519959181808,["yuelong.chen@EIBJDE0195",[[-1,5517,"\\"]],[5517,5517],[5517,5517]]],[1519959183321,["yuelong.chen@EIBJDE0195",[[-1,5524,"\\"]],[5524,5524],[5524,5524]]],[1519959185935,["yuelong.chen@EIBJDE0195",[[-1,5539,"\\"]],[5539,5539],[5539,5539]]],[1519959187512,["yuelong.chen@EIBJDE0195",[[-1,5541,"\\"]],[5541,5541],[5541,5541]]],[1519959189239,["yuelong.chen@EIBJDE0195",[[-1,5551,"\\"]],[5551,5551],[5551,5551]]],[1519959458528,["yuelong.chen@EIBJDE0195",[[-1,5469,"\\"]],[5470,5470],[5469,5469]]],[1519959468119,["yuelong.chen@EIBJDE0195",[[-1,5533,"\\"]],[5534,5534],[5533,5533]]],[1519959475959,["yuelong.chen@EIBJDE0195",[[-1,5520,"\\"]],[5521,5521],[5520,5520]]],[1519959486299,["yuelong.chen@EIBJDE0195",[[1,5556,"\\"]],[5556,5556],[5557,5557]]],[1519959488386,["yuelong.chen@EIBJDE0195",[[-1,5556,"\\"]],[5557,5557],[5556,5556]]],[1519959488850,["yuelong.chen@EIBJDE0195",[[-1,5556,"\n"]],[5556,5556],[5555,5555]]],[1519959491879,["yuelong.chen@EIBJDE0195",[[-1,5386,"\n"]],[5386,5386],[5385,5385]]],[1519959498696,["yuelong.chen@EIBJDE0195",[[-1,5498,"\\"]],[5499,5499],[5498,5498]]],[1519959504639,["yuelong.chen@EIBJDE0195",[[-1,5062,"\n"]],[5062,5062],[5061,5061]]],[1519959506471,["yuelong.chen@EIBJDE0195",[[-1,5021,"\n"]],[5021,5021],[5020,5020]]]]],["0842f23f-83c3-457a-81cd-7b3d45a94327",1519959963374,"---\nstyle: plain\n---\n\n# Systematic bias of correlation coefficient may explain negative accuracy of genomic prediction\n\n## 摘要\n\n基因组预测的准确性一般是基于交叉验证及pearson相关系数来计算。但是有很多`negative accuracies`（不是特别好翻译，后文都用`NA`来代表）出现在研究文章中。`NA`描述的就是当表型和基因型是随机打乱的时候，计算出来的pearson相关系数说描述的准确性，这个值应该是在0左右。文中描述了两种用来计算`NA`的方法（Hold accuracy和Instant accuracy）。利用真实及模拟数据测试，确定两种方法在不同的条件下确实会有偏。最终还提出了一种对于Instant accuracy方法的一种改进。\n\n> Accuracy of genomic prediction is commonly calculated as the Pearson correlation coefficient between the predicted and observed phenotypes in the inference population by using cross-validation analysis. More frequently than expected, significant negative accuracies of genomic prediction have been reported in genomic selection studies. These negative values are surprising, given that the minimum value for prediction accuracy should hover around zero when randomly permuted data sets are analyzed.We reviewed the two common approaches for calculating the Pearson correlation and hypothesized that these negative accuracy values reflect potential bias owing to artifacts caused by the mathematical formulas used to calculate prediction accuracy. The first approach, Instant accuracy, calculates correlations for each fold and reports prediction accuracy as themean of correlations across fold. The other approach, Hold accuracy, predicts all phenotypes in all fold and calculates correlation between the observed and predicted phenotypes at the end of the cross validation process. Using simulated and real data,we demonstrated that our hypothesis is true. Both approaches are biased downward under certain conditions. The biases become larger when more fold are employed and when the expected accuracy is low. The bias of Instant accuracy can be corrected using a modified formula.\n\n## 主要方法描述\n\n### 交叉验证（cross-validation）\n\n将样本分成两个不同的部分，一部分用来做training，一部分用来做test。因为样本本身是有正确标签的，用来做test的样本的预测标签和真实标签之前的差异或者一致性可以用来评估模型的好坏，在模型建立及验证中经常使用。\n\n而将这种分成两个部分的实验重复N次，就是N倍交叉验证。常用的有2 fold-cross-validation、5 fold-cross-validation、10 fold-cross-validation。\n\n以2倍交叉验证为例，例如有样本集合\\[A1，A2，A3，A4，A5，A6\\]，6个样本的样本集合。需要将这个样本集合随机分为2部分（set1=\\[A1,A3,A6\\],set2=\\[A2,A4,A5\\]），先用set1做训练（或者模型构建），在通过模型预测set2，并**计算set2中结果一致性**；再用set2做训练，再通过模型预测set1，并**计算set1中结果一致性**。最终结果来描述模型的好坏。\n\n### Instant accuracy\n\n对于交叉验证，之后结果的评估，一种是分别评估一致性（如上所述），再将一致性取平均。\n\n### Hold accuracy\n\n另一种则是，将所有的预测结果放到一起，再计算一致性。\n\n图示：\n\n![](/images/cross-validation.png)\n\n## 结果\n\n### 数据描述\n\n* 真实数据：4个真实的样本集，包含SNP集合及最终的表型标记\n* 随机数据：利用真实的数据，随机打乱表型标记\n* 模拟数据：缺省\n\n### Artifactual negative correlation between means of references and inferences\n\n文中一般研究均使用的是5倍交叉验证。所以研究者将其中一套真实数据随机分成5个size相同的集合时，分别统计了这5个集合的表型值（吐丝时间：连续值），结果如下图所示：\n\n![](/images/figure1.png)\n\n> Negative correlation between means of references and inferences in cross-validation. The phenotype evaluated was flowering time, measured as DTS, from 260 maize inbred lines. The flowering-time phenotypes were randomly clustered into five evenly-sized groups, indicated by different signs \\(A\\). The phenotypic distribution for each group is illustrated in \\(B\\). The group numbers in \\(B\\) match the group numbers in \\(C\\). The signs in \\(C\\) match the group signs in \\(A\\). The means of inferences are indicated by open signs \\(C\\). The means of the other four groups as references are indicated by the filled signs for each inference group. The means of inference and reference are 100% negatively correlated \\(D\\).\n\n这个描述其实我觉得多余，因为是同一个数据集，当把大的数作为set1的时候，那么set2里的数自然更小。所以他们就是会呈现出一种负相关。\n\n### Negative bias of hold accuracies\n\n遗传性评估：_就是将training set训练出来的模型，直接作用training set，然后看结果一致性_\n\n如前一小节所说，如果training set中的表型均值越大，那么test set中的表型均值则越小。又因为training set中的表型均值更大一些，所以所训练出来的模型就更倾向于预测test set更大的值。有这些关系可以推断出，如果直接使用`Hold accuracies`进行评估，本身就会有一些负相关偏好在其中。其结果如下图所示：\n\n![](/images/figure2.png)\n\n> ABC图表示的训练出的模型对training set作用所获得的结果。DEF则是对test set作用所获得结果。\n\n能从F图中看出，利用`Hold accuracy`的确会有一个偏好。\n\n### More fold leads to more bias using hold accuracy\n\n利用交叉验证，使用的倍数越多（More fold），则偏好越大，如下图所示：\n\n![](/images/figure3.png)\n\n### Differences in prediction accuracy between Hold and Instant approaches\n\n> We extended our examination to scenarios with expected prediction accuracies above zero by using phenotypes simulated from real maize genotypes.\n\n这一部分我的理解是：对于一个数据集，本身是有真实表型的（假设SNP及表型集是100%相关的），然后将本身的真实表型部分打乱，最终达到一个相关度0.125~0.75。然后在按照之前的方法进行分析，同样还会逐步改变样本数目。结果如下图所  \n示：\n\n![](/images/figure4.png)\n\n可以发现，这些条件的变化，Instant accuracy都要比Hold accuracy要高。而且在同样的继承性的条件下，样本数目越多，准确度越高。\n\n### Problems unique to Instant accuracy\n\n前几小节的结论都是Instant accuracy的结果要比Hold accuracy好。但也不是代表Instant accuracy没有问题。由于它是分每一次做一个相关性，然后计算相关性的均值。由于本身pearson相关系数的特性，就是对于小样本量，相关系数会有偏（Fisher大  \n神说的），所以当样本量很少的情况下，Instant accuracy结果就会出现问题。如下图所示：\n\n![](/images/figure5.png)\n\n从上图中，可以发现，随着fold数目的增加，test set中的样本越来越少（fold数越多，相当于将样本集平均分成了多少份）准确性会下降。而且这种下降不是由于模型出问题（因为training set的样本数大，所以模型应该是更好的），而只能是算法出现了问题。\n\n### Correcting Instant accuracy toward unbiased estimation\n\n文中使用了一个矫正方法（并非作者发明，而是之前其他人发表，但是并没有用到这项评估中，所以作者提议以后加入这项矫正），结果就要好的多，但是因为是计算pearson相关系数，所以还是有一定的数目限制，至少test set中要包含5个样本以上。结果如上图中的黑线。\n\n矫正公式如下：\n\n$$\n\\widehat{p}=r[1+\\frac{(1-r^2)}{2(n-4)}]\n$$\n\n其中n为样本数，r为pearson相关系数\n\n## 讨论\n\n### Biased Hold accuracy under the null hypothesis\n\n前人研究中只是展示了偏好，但是并没有分析出原因。\n\n## Take Home Message\n\n1. 因为几乎没有做过此类研究，所以算第一次看到用相关系数来评判模型好坏的文章，之后如果用于机器学习，regression可以尝试用这种方法来评估性能。\n2. 有些差异就是机器学习的regression都是利用差值来进行寻找最小误差，从而获得最优模型。最终评估结果也是利用差异大小来评估，使用差值就不存在Instant accuracy和Hold accuracy了。\n\n$$\n\\frac{\\frac{(x_1-\\hat{x})^2+(x_2-\\hat{x})^2}{2}+\\frac{(x_3-\\hat{x})^2+(x_4-\\hat{x})^2}{2}}{2}=\\frac{(x_1-\\hat{x})^2+(x_2-\\hat{x})^2+(x_3-\\hat{x})^2+(x_4-\\hat{x})^2}{4}\n$$\n\n上述是一样的。所以利用差值是不存在这种情况。以后如果做类似的工作，可以试试使用pearson相关系数来进行结果评估。\n\n",[[1519959955808,["yuelong.chen@EIBJDE0195",[[1,5021,"\n"]],[5020,5020],[5021,5021]]],[1519959959446,["yuelong.chen@EIBJDE0195",[[1,5062,"\n"]],[5061,5061],[5062,5062]]],[1519959960815,["yuelong.chen@EIBJDE0195",[[1,5386,"\n"]],[5385,5385],[5386,5386]]],[1519959962145,["yuelong.chen@EIBJDE0195",[[1,5555,"\n"]],[5554,5554],[5555,5555]]]]],["39945650-840a-4e77-97d0-859288b21257",1519960193500,"---\nstyle: plain\n---\n\n# Systematic bias of correlation coefficient may explain negative accuracy of genomic prediction\n\n## 摘要\n\n基因组预测的准确性一般是基于交叉验证及pearson相关系数来计算。但是有很多`negative accuracies`（不是特别好翻译，后文都用`NA`来代表）出现在研究文章中。`NA`描述的就是当表型和基因型是随机打乱的时候，计算出来的pearson相关系数说描述的准确性，这个值应该是在0左右。文中描述了两种用来计算`NA`的方法（Hold accuracy和Instant accuracy）。利用真实及模拟数据测试，确定两种方法在不同的条件下确实会有偏。最终还提出了一种对于Instant accuracy方法的一种改进。\n\n> Accuracy of genomic prediction is commonly calculated as the Pearson correlation coefficient between the predicted and observed phenotypes in the inference population by using cross-validation analysis. More frequently than expected, significant negative accuracies of genomic prediction have been reported in genomic selection studies. These negative values are surprising, given that the minimum value for prediction accuracy should hover around zero when randomly permuted data sets are analyzed.We reviewed the two common approaches for calculating the Pearson correlation and hypothesized that these negative accuracy values reflect potential bias owing to artifacts caused by the mathematical formulas used to calculate prediction accuracy. The first approach, Instant accuracy, calculates correlations for each fold and reports prediction accuracy as themean of correlations across fold. The other approach, Hold accuracy, predicts all phenotypes in all fold and calculates correlation between the observed and predicted phenotypes at the end of the cross validation process. Using simulated and real data,we demonstrated that our hypothesis is true. Both approaches are biased downward under certain conditions. The biases become larger when more fold are employed and when the expected accuracy is low. The bias of Instant accuracy can be corrected using a modified formula.\n\n## 主要方法描述\n\n### 交叉验证（cross-validation）\n\n将样本分成两个不同的部分，一部分用来做training，一部分用来做test。因为样本本身是有正确标签的，用来做test的样本的预测标签和真实标签之前的差异或者一致性可以用来评估模型的好坏，在模型建立及验证中经常使用。\n\n而将这种分成两个部分的实验重复N次，就是N倍交叉验证。常用的有2 fold-cross-validation、5 fold-cross-validation、10 fold-cross-validation。\n\n以2倍交叉验证为例，例如有样本集合\\[A1，A2，A3，A4，A5，A6\\]，6个样本的样本集合。需要将这个样本集合随机分为2部分（set1=\\[A1,A3,A6\\],set2=\\[A2,A4,A5\\]），先用set1做训练（或者模型构建），在通过模型预测set2，并**计算set2中结果一致性**；再用set2做训练，再通过模型预测set1，并**计算set1中结果一致性**。最终结果来描述模型的好坏。\n\n### Instant accuracy\n\n对于交叉验证，之后结果的评估，一种是分别评估一致性（如上所述），再将一致性取平均。\n\n### Hold accuracy\n\n另一种则是，将所有的预测结果放到一起，再计算一致性。\n\n图示：\n\n![](/images/cross-validation.png)\n\n## 结果\n\n### 数据描述\n\n* 真实数据：4个真实的样本集，包含SNP集合及最终的表型标记\n* 随机数据：利用真实的数据，随机打乱表型标记\n* 模拟数据：缺省\n\n### Artifactual negative correlation between means of references and inferences\n\n文中一般研究均使用的是5倍交叉验证。所以研究者将其中一套真实数据随机分成5个size相同的集合时，分别统计了这5个集合的表型值（吐丝时间：连续值），结果如下图所示：\n\n![](/images/figure1.png)\n\n> Negative correlation between means of references and inferences in cross-validation. The phenotype evaluated was flowering time, measured as DTS, from 260 maize inbred lines. The flowering-time phenotypes were randomly clustered into five evenly-sized groups, indicated by different signs \\(A\\). The phenotypic distribution for each group is illustrated in \\(B\\). The group numbers in \\(B\\) match the group numbers in \\(C\\). The signs in \\(C\\) match the group signs in \\(A\\). The means of inferences are indicated by open signs \\(C\\). The means of the other four groups as references are indicated by the filled signs for each inference group. The means of inference and reference are 100% negatively correlated \\(D\\).\n\n这个描述其实我觉得多余，因为是同一个数据集，当把大的数作为set1的时候，那么set2里的数自然更小。所以他们就是会呈现出一种负相关。\n\n### Negative bias of hold accuracies\n\n遗传性评估：_就是将training set训练出来的模型，直接作用training set，然后看结果一致性_\n\n如前一小节所说，如果training set中的表型均值越大，那么test set中的表型均值则越小。又因为training set中的表型均值更大一些，所以所训练出来的模型就更倾向于预测test set更大的值。有这些关系可以推断出，如果直接使用`Hold accuracies`进行评估，本身就会有一些负相关偏好在其中。其结果如下图所示：\n\n![](/images/figure2.png)\n\n> ABC图表示的训练出的模型对training set作用所获得的结果。DEF则是对test set作用所获得结果。\n\n能从F图中看出，利用`Hold accuracy`的确会有一个偏好。\n\n### More fold leads to more bias using hold accuracy\n\n利用交叉验证，使用的倍数越多（More fold），则偏好越大，如下图所示：\n\n![](/images/figure3.png)\n\n### Differences in prediction accuracy between Hold and Instant approaches\n\n> We extended our examination to scenarios with expected prediction accuracies above zero by using phenotypes simulated from real maize genotypes.\n\n这一部分我的理解是：对于一个数据集，本身是有真实表型的（假设SNP及表型集是100%相关的），然后将本身的真实表型部分打乱，最终达到一个相关度0.125~0.75。然后在按照之前的方法进行分析，同样还会逐步改变样本数目。结果如下图所  \n示：\n\n![](/images/figure4.png)\n\n可以发现，这些条件的变化，Instant accuracy都要比Hold accuracy要高。而且在同样的继承性的条件下，样本数目越多，准确度越高。\n\n### Problems unique to Instant accuracy\n\n前几小节的结论都是Instant accuracy的结果要比Hold accuracy好。但也不是代表Instant accuracy没有问题。由于它是分每一次做一个相关性，然后计算相关性的均值。由于本身pearson相关系数的特性，就是对于小样本量，相关系数会有偏（Fisher大  \n神说的），所以当样本量很少的情况下，Instant accuracy结果就会出现问题。如下图所示：\n\n![](/images/figure5.png)\n\n从上图中，可以发现，随着fold数目的增加，test set中的样本越来越少（fold数越多，相当于将样本集平均分成了多少份）准确性会下降。而且这种下降不是由于模型出问题（因为training set的样本数大，所以模型应该是更好的），而只能是算法出现了问题。\n\n### Correcting Instant accuracy toward unbiased estimation\n\n文中使用了一个矫正方法（并非作者发明，而是之前其他人发表，但是并没有用到这项评估中，所以作者提议以后加入这项矫正），结果就要好的多，但是因为是计算pearson相关系数，所以还是有一定的数目限制，至少test set中要包含5个样本以上。结果如上图中的黑线。\n\n矫正公式如下：\n\n\n$$\n\\widehat{p}=r[1+\\frac{(1-r^2)}{2(n-4)}]\n$$\n\n\n其中n为样本数，r为pearson相关系数\n\n## 讨论\n\n### Biased Hold accuracy under the null hypothesis\n\n前人研究中只是展示了偏好，但是并没有分析出原因。\n\n## Take Home Message\n\n1. 因为几乎没有做过此类研究，所以算第一次看到用相关系数来评判模型好坏的文章，之后如果用于机器学习，regression可以尝试用这种方法来评估性能。\n2. 有些差异就是机器学习的regression都是利用差值来进行寻找最小误差，从而获得最优模型。最终评估结果也是利用差异大小来评估，使用差值就不存在Instant accuracy和Hold accuracy了。\n\n\n$$\n\\frac{\\frac{(x_1-\\hat{x})^2+(x_2-\\hat{x})^2}{2}+\\frac{(x_3-\\hat{x})^2+(x_4-\\hat{x})^2}{2}}{2}=\\frac{(x_1-\\hat{x})^2+(x_2-\\hat{x})^2+(x_3-\\hat{x})^2+(x_4-\\hat{x})^2}{4}\n$$\n\n\n上述是一样的。所以利用差值是不存在这种情况。以后如果做类似的工作，可以试试使用pearson相关系数来进行结果评估。\n\n\n\n\n$$\n\\frac{x}{y}*x = y\n$$\n\n\n",[[1519960192097,["yuelong.chen@EIBJDE0195",[[-1,5623,"$$\n\\frac{x}{y}*x = y\n$$"]],[5623,5646],[5623,5623]]]]],["9af5f94a-7194-426b-86cf-fcd1086762dd",1519969828448,"---\nstyle: plain\n---\n\n# Systematic bias of correlation coefficient may explain negative accuracy of genomic prediction\n\n## 摘要\n\n基因组预测的准确性一般是基于交叉验证及pearson相关系数来计算。但是有很多`negative accuracies`（不是特别好翻译，后文都用`NA`来代表）出现在研究文章中。`NA`描述的就是当表型和基因型是随机打乱的时候，计算出来的pearson相关系数说描述的准确性，这个值应该是在0左右。文中描述了两种用来计算`NA`的方法（Hold accuracy和Instant accuracy）。利用真实及模拟数据测试，确定两种方法在不同的条件下确实会有偏。最终还提出了一种对于Instant accuracy方法的一种改进。\n\n> Accuracy of genomic prediction is commonly calculated as the Pearson correlation coefficient between the predicted and observed phenotypes in the inference population by using cross-validation analysis. More frequently than expected, significant negative accuracies of genomic prediction have been reported in genomic selection studies. These negative values are surprising, given that the minimum value for prediction accuracy should hover around zero when randomly permuted data sets are analyzed.We reviewed the two common approaches for calculating the Pearson correlation and hypothesized that these negative accuracy values reflect potential bias owing to artifacts caused by the mathematical formulas used to calculate prediction accuracy. The first approach, Instant accuracy, calculates correlations for each fold and reports prediction accuracy as themean of correlations across fold. The other approach, Hold accuracy, predicts all phenotypes in all fold and calculates correlation between the observed and predicted phenotypes at the end of the cross validation process. Using simulated and real data,we demonstrated that our hypothesis is true. Both approaches are biased downward under certain conditions. The biases become larger when more fold are employed and when the expected accuracy is low. The bias of Instant accuracy can be corrected using a modified formula.\n\n## 主要方法描述\n\n### 交叉验证（cross-validation）\n\n将样本分成两个不同的部分，一部分用来做training，一部分用来做test。因为样本本身是有正确标签的，用来做test的样本的预测标签和真实标签之前的差异或者一致性可以用来评估模型的好坏，在模型建立及验证中经常使用。\n\n而将这种分成两个部分的实验重复N次，就是N倍交叉验证。常用的有2 fold-cross-validation、5 fold-cross-validation、10 fold-cross-validation。\n\n以2倍交叉验证为例，例如有样本集合\\[A1，A2，A3，A4，A5，A6\\]，6个样本的样本集合。需要将这个样本集合随机分为2部分（set1=\\[A1,A3,A6\\],set2=\\[A2,A4,A5\\]），先用set1做训练（或者模型构建），在通过模型预测set2，并**计算set2中结果一致性**；再用set2做训练，再通过模型预测set1，并**计算set1中结果一致性**。最终结果来描述模型的好坏。\n\n### Instant accuracy\n\n对于交叉验证，之后结果的评估，一种是分别评估一致性（如上所述），再将一致性取平均。\n\n### Hold accuracy\n\n另一种则是，将所有的预测结果放到一起，再计算一致性。\n\n图示：\n\n![](/images/cross-validation.png)\n\n## 结果\n\n### 数据描述\n\n* 真实数据：4个真实的样本集，包含SNP集合及最终的表型标记\n* 随机数据：利用真实的数据，随机打乱表型标记\n* 模拟数据：缺省\n\n### Artifactual negative correlation between means of references and inferences\n\n文中一般研究均使用的是5倍交叉验证。所以研究者将其中一套真实数据随机分成5个size相同的集合时，分别统计了这5个集合的表型值（吐丝时间：连续值），结果如下图所示：\n\n![](/images/figure1.png)\n\n> Negative correlation between means of references and inferences in cross-validation. The phenotype evaluated was flowering time, measured as DTS, from 260 maize inbred lines. The flowering-time phenotypes were randomly clustered into five evenly-sized groups, indicated by different signs \\(A\\). The phenotypic distribution for each group is illustrated in \\(B\\). The group numbers in \\(B\\) match the group numbers in \\(C\\). The signs in \\(C\\) match the group signs in \\(A\\). The means of inferences are indicated by open signs \\(C\\). The means of the other four groups as references are indicated by the filled signs for each inference group. The means of inference and reference are 100% negatively correlated \\(D\\).\n\n这个描述其实我觉得多余，因为是同一个数据集，当把大的数作为set1的时候，那么set2里的数自然更小。所以他们就是会呈现出一种负相关。\n\n### Negative bias of hold accuracies\n\n遗传性评估：_就是将training set训练出来的模型，直接作用training set，然后看结果一致性_\n\n如前一小节所说，如果training set中的表型均值越大，那么test set中的表型均值则越小。又因为training set中的表型均值更大一些，所以所训练出来的模型就更倾向于预测test set更大的值。有这些关系可以推断出，如果直接使用`Hold accuracies`进行评估，本身就会有一些负相关偏好在其中。其结果如下图所示：\n\n![](/images/figure2.png)\n\n> ABC图表示的训练出的模型对training set作用所获得的结果。DEF则是对test set作用所获得结果。\n\n能从F图中看出，利用`Hold accuracy`的确会有一个偏好。\n\n### More fold leads to more bias using hold accuracy\n\n利用交叉验证，使用的倍数越多（More fold），则偏好越大，如下图所示：\n\n![](/images/figure3.png)\n\n### Differences in prediction accuracy between Hold and Instant approaches\n\n> We extended our examination to scenarios with expected prediction accuracies above zero by using phenotypes simulated from real maize genotypes.\n\n这一部分我的理解是：对于一个数据集，本身是有真实表型的（假设SNP及表型集是100%相关的），然后将本身的真实表型部分打乱，最终达到一个相关度0.125~0.75。然后在按照之前的方法进行分析，同样还会逐步改变样本数目。结果如下图所  \n示：\n\n![](/images/figure4.png)\n\n可以发现，这些条件的变化，Instant accuracy都要比Hold accuracy要高。而且在同样的继承性的条件下，样本数目越多，准确度越高。\n\n### Problems unique to Instant accuracy\n\n前几小节的结论都是Instant accuracy的结果要比Hold accuracy好。但也不是代表Instant accuracy没有问题。由于它是分每一次做一个相关性，然后计算相关性的均值。由于本身pearson相关系数的特性，就是对于小样本量，相关系数会有偏（Fisher大  \n神说的），所以当样本量很少的情况下，Instant accuracy结果就会出现问题。如下图所示：\n\n![](/images/figure5.png)\n\n从上图中，可以发现，随着fold数目的增加，test set中的样本越来越少（fold数越多，相当于将样本集平均分成了多少份）准确性会下降。而且这种下降不是由于模型出问题（因为training set的样本数大，所以模型应该是更好的），而只能是算法出现了问题。\n\n### Correcting Instant accuracy toward unbiased estimation\n\n文中使用了一个矫正方法（并非作者发明，而是之前其他人发表，但是并没有用到这项评估中，所以作者提议以后加入这项矫正），结果就要好的多，但是因为是计算pearson相关系数，所以还是有一定的数目限制，至少test set中要包含5个样本以上。结果如上图中的黑线。\n\n矫正公式如下：\n\n\n$$\n\\widehat{p}=r[1+\\frac{(1-r^2)}{2(n-4)}]\n$$\n\n\n其中n为样本数，r为pearson相关系数\n\n## 讨论\n\n### Biased Hold accuracy under the null hypothesis\n\n前人研究中只是展示了偏好，但是并没有分析出原因。\n\n## Take Home Message\n\n1. 因为几乎没有做过此类研究，所以算第一次看到用相关系数来评判模型好坏的文章，之后如果用于机器学习，regression可以尝试用这种方法来评估性能。\n2. 有些差异就是机器学习的regression都是利用差值来进行寻找最小误差，从而获得最优模型。最终评估结果也是利用差异大小来评估，使用差值就不存在Instant accuracy和Hold accuracy了。\n\n\n$$\n\\frac{\\frac{(x_1-\\hat{x})^2+(x_2-\\hat{x})^2}{2}+\\frac{(x_3-\\hat{x})^2+(x_4-\\hat{x})^2}{2}}{2}=\\frac{(x_1-\\hat{x})^2+(x_2-\\hat{x})^2+(x_3-\\hat{x})^2+(x_4-\\hat{x})^2}{4}\n$$\n\n\n上述是一样的。所以利用差值是不存在这种情况。以后如果做类似的工作，可以试试使用pearson相关系数来进行结果评估。\n\n\n\n\n\n\n\n",[[1519969798403,["yuelong.chen@EIBJDE0195",[[-1,5384,"$$"],[1,5386,"{%"]],[5384,5386],[5386,5386]]],[1519969801437,["yuelong.chen@EIBJDE0195",[[1,5557,"ss"]],[5557,5557],[5559,5559]]],[1519969802374,["yuelong.chen@EIBJDE0195",[[-1,5555,"$$ss"]],[5559,5559],[5555,5555]]],[1519969803982,["yuelong.chen@EIBJDE0195",[[1,5555,"%}"]],[5555,5555],[5557,5557]]],[1519969806656,["yuelong.chen@EIBJDE0195",[[-1,5554,"\n"]],[5555,5555],[5554,5554]]],[1519969807860,["yuelong.chen@EIBJDE0195",[[1,5554," "]],[5554,5554],[5555,5555]]],[1519969809982,["yuelong.chen@EIBJDE0195",[[-1,5386,"\n"]],[5386,5386],[5386,5386]]],[1519969810883,["yuelong.chen@EIBJDE0195",[[1,5386," "]],[5386,5386],[5387,5387]]],[1519969818802,["yuelong.chen@EIBJDE0195",[[-1,5019,"$$"],[1,5021,"{%"]],[5019,5021],[5021,5021]]],[1519969821135,["yuelong.chen@EIBJDE0195",[[-1,5021,"\n"]],[5022,5022],[5021,5021]]],[1519969821278,["yuelong.chen@EIBJDE0195",[[1,5021," "]],[5021,5021],[5022,5022]]],[1519969823599,["yuelong.chen@EIBJDE0195",[[-1,5062,"$$"]],[5062,5064],[5062,5062]]],[1519969824359,["yuelong.chen@EIBJDE0195",[[-1,5064,"\n"]],[5062,5062],[5061,5061]]],[1519969827695,["yuelong.chen@EIBJDE0195",[[1,5061," %}"]],[5061,5061],[5064,5064]]],[1519969926235,["yuelong.chen@EIBJDE0195",[[-1,5384,"{%"],[1,5386,"$$"]],[5384,5386],[5386,5386]]],[1519969928384,["yuelong.chen@EIBJDE0195",[[-1,5555,"%}"],[1,5557,"$$"]],[5555,5557],[5557,5557]]],[1519969932584,["yuelong.chen@EIBJDE0195",[[-1,5019,"{% "],[1,5022,"$$"]],[5019,5022],[5021,5021]]],[1519969934654,["yuelong.chen@EIBJDE0195",[[-1,5061,"%}"],[1,5063,"$$"]],[5061,5063],[5063,5063]]],[1519969937427,["yuelong.chen@EIBJDE0195",[[1,5021," "]],[5021,5021],[5022,5022]]]]]]}